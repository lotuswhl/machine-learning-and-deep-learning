{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lotuswhl/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_raw = 'He is the king . The king is royal . The queen is royal . She is the royal  queen '"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 将输入文本转换为小写"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_raw = corpus_raw.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 构建文本的词典"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for word in corpus_raw.split():\n",
    "    if word != '.': # 不将标点看做单词\n",
    "        words.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['he',\n",
       " 'is',\n",
       " 'the',\n",
       " 'king',\n",
       " 'the',\n",
       " 'king',\n",
       " 'is',\n",
       " 'royal',\n",
       " 'the',\n",
       " 'queen',\n",
       " 'is',\n",
       " 'royal',\n",
       " 'she',\n",
       " 'is',\n",
       " 'the',\n",
       " 'royal',\n",
       " 'queen']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = set(words) # 去除重复词汇"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'he', 'is', 'king', 'queen', 'royal', 'she', 'the'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下来构建单词与数字的相互映射词典"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2num={}\n",
    "num2word={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for num,word in enumerate(words):\n",
    "    word2num[word]=num\n",
    "    num2word[num]=word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "做下测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2num['royal']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'the'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num2word[5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下来将我们的语料库逐句转换为词汇表示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sentence in corpus_raw.split('.'):\n",
    "    sentences.append(sentence.split())\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['he', 'is', 'the', 'king'],\n",
       " ['the', 'king', 'is', 'royal'],\n",
       " ['the', 'queen', 'is', 'royal'],\n",
       " ['she', 'is', 'the', 'royal', 'queen']]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 接下来我们要生成训练数据\n",
    "我们将使用skip-gram 算法,也就是根据输入词汇预测其周围词汇的概率\n",
    "因此 我们需要根据上面分隔好的词汇组成的句子去生成诸如{'he','is'},{'he','the'}这样的词组;具体的取决于gram window size的大小,从而决定一个单词生成几个词组"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=[]\n",
    "WINDOW_SIZE=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sentence in sentences:\n",
    "    for word_index,word in enumerate(sentence):\n",
    "        for ng_word in sentence[max(0,word_index-WINDOW_SIZE):\n",
    "                                min(word_index+WINDOW_SIZE+1,len(sentence))]:\n",
    "            if ng_word != word:\n",
    "                data.append([word,ng_word])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['he', 'is'],\n",
       " ['he', 'the'],\n",
       " ['is', 'he'],\n",
       " ['is', 'the'],\n",
       " ['is', 'king'],\n",
       " ['the', 'he'],\n",
       " ['the', 'is'],\n",
       " ['the', 'king'],\n",
       " ['king', 'is'],\n",
       " ['king', 'the'],\n",
       " ['the', 'king'],\n",
       " ['the', 'is'],\n",
       " ['king', 'the'],\n",
       " ['king', 'is'],\n",
       " ['king', 'royal'],\n",
       " ['is', 'the'],\n",
       " ['is', 'king'],\n",
       " ['is', 'royal'],\n",
       " ['royal', 'king'],\n",
       " ['royal', 'is'],\n",
       " ['the', 'queen'],\n",
       " ['the', 'is'],\n",
       " ['queen', 'the'],\n",
       " ['queen', 'is'],\n",
       " ['queen', 'royal'],\n",
       " ['is', 'the'],\n",
       " ['is', 'queen'],\n",
       " ['is', 'royal'],\n",
       " ['royal', 'queen'],\n",
       " ['royal', 'is'],\n",
       " ['she', 'is'],\n",
       " ['she', 'the'],\n",
       " ['is', 'she'],\n",
       " ['is', 'the'],\n",
       " ['is', 'royal'],\n",
       " ['the', 'she'],\n",
       " ['the', 'is'],\n",
       " ['the', 'royal'],\n",
       " ['the', 'queen'],\n",
       " ['royal', 'is'],\n",
       " ['royal', 'the'],\n",
       " ['royal', 'queen'],\n",
       " ['queen', 'the'],\n",
       " ['queen', 'royal']]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "vacabulary_size = len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_oneHot(index,vacab_size):\n",
    "    oneHot_vec = np.zeros(vacab_size)\n",
    "    oneHot_vec[index]=1\n",
    "    return oneHot_vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下来构建我们的训练数据,也就是将词组转换成onehot向量构成的向量组"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = []\n",
    "train_y = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "for word_pair in data:\n",
    "    train_x.append(to_oneHot(word2num[word_pair[0]],vacabulary_size))\n",
    "    train_y.append(to_oneHot(word2num[word_pair[1]],vacabulary_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "再将他们转换成numpy数组方面后续操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = np.asarray(train_x)\n",
    "train_y = np.asarray(train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]]\n",
      "[[1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(train_x[0:5])\n",
    "print(train_y[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(44, 7)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(44, 7)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "有了训练数据,现在就可以构建我们的网络了"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=tf.placeholder(tf.float32,shape=[None,vacabulary_size])\n",
    "y_=tf.placeholder(tf.float32,shape=[None,vacabulary_size])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们将要构建一个网络,只有一层隐层,然后使用这一层隐层的值作为我们的目标embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_size=hidden_size=5 # 因为我们的词汇量vacabulary_size为7,所以我们希望构建一个小于他的向量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1 = tf.Variable(tf.random_normal(shape=[vacabulary_size,embedding_size]))\n",
    "b1 = tf.Variable(tf.random_normal(shape=[embedding_size])) # biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_layer = tf.add(tf.matmul(x,w1),b1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2 = tf.Variable(tf.random_normal(shape=[embedding_size,vacabulary_size]))\n",
    "b2 = tf.Variable(tf.random_normal(shape=[vacabulary_size]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = tf.add(tf.matmul(hidden_layer,w2),b2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_softmax = tf.nn.softmax(y_pred,axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "所以,我们的目标是实现one_hot vector --> embedings  --> input word neighbor probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cross entropy loss define\n",
    "cross_entropy_loss = tf.reduce_mean(-tf.reduce_sum(y_*tf.log(y_softmax),axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use gradient descent optimizer\n",
    "optim = tf.train.GradientDescentOptimizer(0.1).minimize(cross_entropy_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "nIters = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss is : 3.713114\n",
      "loss is : 1.3740807\n",
      "loss is : 1.3653294\n",
      "loss is : 1.3636146\n",
      "loss is : 1.3629444\n",
      "loss is : 1.3625973\n",
      "loss is : 1.3623884\n",
      "loss is : 1.3622497\n",
      "loss is : 1.3621517\n",
      "loss is : 1.3620791\n",
      "train done!\n"
     ]
    }
   ],
   "source": [
    "for i in range(nIters):\n",
    "    sess.run(optim,feed_dict={x:train_x,y_:train_y})\n",
    "    if i% 1000 ==0:\n",
    "        print(\"loss is :\",sess.run(cross_entropy_loss,feed_dict={x:train_x,y_:train_y}))\n",
    "print(\"train done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2.0404618  -2.8020809   0.60984844  0.93457043  0.18032508]\n",
      " [ 2.3382154   0.58353245 -0.5876934  -0.13913979  1.2269977 ]\n",
      " [-1.0649415   1.4285247  -0.41733813 -0.23755352 -0.20523444]\n",
      " [-1.3687102  -1.3037876  -1.1744163   0.596278    0.0518599 ]\n",
      " [-1.9236883  -0.01062022  1.3702127  -0.23605892  0.99357176]\n",
      " [ 0.2056583  -1.2235731   0.8092315  -2.7232547   0.9354071 ]\n",
      " [-0.7842573   0.95953614  0.40230122  0.42348516  1.3618242 ]]\n"
     ]
    }
   ],
   "source": [
    "print(sess.run(w1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.668807    1.5817069   1.2045853   0.9268311   0.86226654]\n"
     ]
    }
   ],
   "source": [
    "print(sess.run(b1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = w1+b1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.3716547  -1.220374    1.8144338   1.8614016   1.0425916 ]\n",
      " [ 1.6694083   2.1652393   0.6168919   0.78769135  2.0892644 ]\n",
      " [-1.7337486   3.0102315   0.7872472   0.6892776   0.65703213]\n",
      " [-2.037517    0.2779193   0.03016901  1.5231092   0.91412646]\n",
      " [-2.5924954   1.5710866   2.574798    0.6907722   1.8558383 ]\n",
      " [-0.4631487   0.3581338   2.0138168  -1.7964236   1.7976737 ]\n",
      " [-1.4530643   2.541243    1.6068865   1.3503163   2.2240906 ]]\n"
     ]
    }
   ],
   "source": [
    "print(sess.run(embeddings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.7337486 ,  3.0102315 ,  0.7872472 ,  0.6892776 ,  0.65703213],\n",
       "       [-1.7337486 ,  3.0102315 ,  0.7872472 ,  0.6892776 ,  0.65703213],\n",
       "       [ 1.3716547 , -1.220374  ,  1.8144338 ,  1.8614016 ,  1.0425916 ],\n",
       "       [ 1.3716547 , -1.220374  ,  1.8144338 ,  1.8614016 ,  1.0425916 ],\n",
       "       [ 1.3716547 , -1.220374  ,  1.8144338 ,  1.8614016 ,  1.0425916 ],\n",
       "       [-0.4631487 ,  0.3581338 ,  2.0138168 , -1.7964236 ,  1.7976737 ],\n",
       "       [-0.4631487 ,  0.3581338 ,  2.0138168 , -1.7964236 ,  1.7976737 ],\n",
       "       [-0.4631487 ,  0.3581338 ,  2.0138168 , -1.7964236 ,  1.7976737 ],\n",
       "       [-2.5924954 ,  1.5710866 ,  2.574798  ,  0.6907722 ,  1.8558383 ],\n",
       "       [-2.5924954 ,  1.5710866 ,  2.574798  ,  0.6907722 ,  1.8558383 ],\n",
       "       [-0.4631487 ,  0.3581338 ,  2.0138168 , -1.7964236 ,  1.7976737 ],\n",
       "       [-0.4631487 ,  0.3581338 ,  2.0138168 , -1.7964236 ,  1.7976737 ],\n",
       "       [-2.5924954 ,  1.5710866 ,  2.574798  ,  0.6907722 ,  1.8558383 ],\n",
       "       [-2.5924954 ,  1.5710866 ,  2.574798  ,  0.6907722 ,  1.8558383 ],\n",
       "       [-2.5924954 ,  1.5710866 ,  2.574798  ,  0.6907722 ,  1.8558383 ],\n",
       "       [ 1.3716547 , -1.220374  ,  1.8144338 ,  1.8614016 ,  1.0425916 ],\n",
       "       [ 1.3716547 , -1.220374  ,  1.8144338 ,  1.8614016 ,  1.0425916 ],\n",
       "       [ 1.3716547 , -1.220374  ,  1.8144338 ,  1.8614016 ,  1.0425916 ],\n",
       "       [ 1.6694083 ,  2.1652393 ,  0.6168919 ,  0.78769135,  2.0892644 ],\n",
       "       [ 1.6694083 ,  2.1652393 ,  0.6168919 ,  0.78769135,  2.0892644 ],\n",
       "       [-0.4631487 ,  0.3581338 ,  2.0138168 , -1.7964236 ,  1.7976737 ],\n",
       "       [-0.4631487 ,  0.3581338 ,  2.0138168 , -1.7964236 ,  1.7976737 ],\n",
       "       [-2.037517  ,  0.2779193 ,  0.03016901,  1.5231092 ,  0.91412646],\n",
       "       [-2.037517  ,  0.2779193 ,  0.03016901,  1.5231092 ,  0.91412646],\n",
       "       [-2.037517  ,  0.2779193 ,  0.03016901,  1.5231092 ,  0.91412646],\n",
       "       [ 1.3716547 , -1.220374  ,  1.8144338 ,  1.8614016 ,  1.0425916 ],\n",
       "       [ 1.3716547 , -1.220374  ,  1.8144338 ,  1.8614016 ,  1.0425916 ],\n",
       "       [ 1.3716547 , -1.220374  ,  1.8144338 ,  1.8614016 ,  1.0425916 ],\n",
       "       [ 1.6694083 ,  2.1652393 ,  0.6168919 ,  0.78769135,  2.0892644 ],\n",
       "       [ 1.6694083 ,  2.1652393 ,  0.6168919 ,  0.78769135,  2.0892644 ],\n",
       "       [-1.4530643 ,  2.541243  ,  1.6068865 ,  1.3503163 ,  2.2240906 ],\n",
       "       [-1.4530643 ,  2.541243  ,  1.6068865 ,  1.3503163 ,  2.2240906 ],\n",
       "       [ 1.3716547 , -1.220374  ,  1.8144338 ,  1.8614016 ,  1.0425916 ],\n",
       "       [ 1.3716547 , -1.220374  ,  1.8144338 ,  1.8614016 ,  1.0425916 ],\n",
       "       [ 1.3716547 , -1.220374  ,  1.8144338 ,  1.8614016 ,  1.0425916 ],\n",
       "       [-0.4631487 ,  0.3581338 ,  2.0138168 , -1.7964236 ,  1.7976737 ],\n",
       "       [-0.4631487 ,  0.3581338 ,  2.0138168 , -1.7964236 ,  1.7976737 ],\n",
       "       [-0.4631487 ,  0.3581338 ,  2.0138168 , -1.7964236 ,  1.7976737 ],\n",
       "       [-0.4631487 ,  0.3581338 ,  2.0138168 , -1.7964236 ,  1.7976737 ],\n",
       "       [ 1.6694083 ,  2.1652393 ,  0.6168919 ,  0.78769135,  2.0892644 ],\n",
       "       [ 1.6694083 ,  2.1652393 ,  0.6168919 ,  0.78769135,  2.0892644 ],\n",
       "       [ 1.6694083 ,  2.1652393 ,  0.6168919 ,  0.78769135,  2.0892644 ],\n",
       "       [-2.037517  ,  0.2779193 ,  0.03016901,  1.5231092 ,  0.91412646],\n",
       "       [-2.037517  ,  0.2779193 ,  0.03016901,  1.5231092 ,  0.91412646]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(hidden_layer,feed_dict={x:train_x,y_:train_y})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "[-2.5924954  1.5710866  2.574798   0.6907722  1.8558383]\n"
     ]
    }
   ],
   "source": [
    "king_num = word2num['king']\n",
    "print(king_num)\n",
    "king_embedding = embeddings[king_num]\n",
    "print(sess.run(king_embedding))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = sess.run(embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "next,let's have some fun with thoese embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidien_distance(vec1,vec2):\n",
    "    return np.sqrt(np.sum(np.square(vec1-vec2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_closest_embedding(word_index,embeddings):\n",
    "    query_embedding = embeddings[word_index]\n",
    "    \n",
    "    min_distance = 100000\n",
    "    min_index = -1 # 最近的embedding的index\n",
    "    for index,embedding in enumerate(embeddings):\n",
    "        if not np.array_equal(embedding,query_embedding):\n",
    "            distance = euclidien_distance(embedding,query_embedding)\n",
    "            if distance < min_distance:\n",
    "                min_distance = distance\n",
    "                min_index = index\n",
    "    return min_index\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "closest_index_to_king = find_closest_embedding(king_num,embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "she\n"
     ]
    }
   ],
   "source": [
    "print(num2word[closest_index_to_king])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "he\n"
     ]
    }
   ],
   "source": [
    "print(num2word[find_closest_embedding(word2num['queen'],embeddings)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "she\n"
     ]
    }
   ],
   "source": [
    "print(num2word[find_closest_embedding(word2num['king'],embeddings)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "she\n"
     ]
    }
   ],
   "source": [
    "print(num2word[find_closest_embedding(word2num['royal'],embeddings)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "king\n"
     ]
    }
   ],
   "source": [
    "print(num2word[find_closest_embedding(word2num['she'],embeddings)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "让我们来看看这些词向量之间的关系"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用tsne model来降维观察\n",
    "tsne_model = TSNE(n_components=2,random_state=0)\n",
    "np.set_printoptions(suppress=True) # 0 to 0\n",
    "embeddings = tsne_model.fit_transform(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 然后需要对词向量进行归一化,方便matplotlib显示\n",
    "from sklearn import preprocessing\n",
    "norm = preprocessing.Normalizer()\n",
    "embeddings = norm.fit_transform(embeddings,'l2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "is 0.9003202 -0.43522823\n",
      "royal -0.9410435 0.33828554\n",
      "he -0.097218975 -0.99526304\n",
      "queen 0.8215789 0.5700948\n",
      "king -0.7727457 -0.6347157\n",
      "the -0.13745865 0.9905075\n",
      "she 0.113266796 -0.9935646\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fdaf5dd4d68>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig,axes = plt.subplots()\n",
    "plt.xlim((-2,2))\n",
    "plt.ylim((-2,2))\n",
    "for word in words:\n",
    "    print(word,embeddings[word2num[word]][0],embeddings[word2num[word]][1])\n",
    "    axes.annotate(word,(embeddings[word2num[word]][0],embeddings[word2num[word]][1]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
